{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a461bd-d676-4c7b-b274-6c21c6764a87",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5019d49f-fb49-4492-9b03-f51ee9028793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as nplearn_tf\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582df7d2-ac94-4d00-b6ea-a44d296491e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preferences\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f0366e-4751-48d6-b690-53cf4a13512f",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f26d42-ec5b-469b-ad12-71109f23c953",
   "metadata": {},
   "source": [
    "Images from Kaggle competition: https://www.kaggle.com/c/dogs-vs-cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25992abf-3ba2-422d-9f0e-3bfd61956297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize data into train, valid, test dirs\n",
    "os.chdir(\"data/dogs-vs-cats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ecf8e6d-8d65-4388-a3e0-13eb12817312",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"train/dog\") is False:\n",
    "    os.makedirs(\"train/dog\")\n",
    "    os.makedirs(\"train/cat\")\n",
    "    os.makedirs(\"val/dog\")\n",
    "    os.makedirs(\"val/cat\")\n",
    "    os.makedirs(\"test/dog\")\n",
    "    os.makedirs(\"test/cat\")\n",
    "    \n",
    "    for c in random.sample(glob.glob(\"train1/cat*\"), 1000):\n",
    "        shutil.move(c, \"train/cat\" )\n",
    "    for c in random.sample(glob.glob(\"train1/dog*\"), 1000):\n",
    "        shutil.move(c, \"train/dog\" )\n",
    "    \n",
    "    for c in random.sample(glob.glob(\"train1/cat*\"), 500):\n",
    "        shutil.move(c, \"val/cat\" )\n",
    "    for c in random.sample(glob.glob(\"train1/dog*\"), 500):\n",
    "        shutil.move(c, \"val/dog\" )\n",
    "    \n",
    "    for c in random.sample(glob.glob(\"train1/cat*\"), 100):\n",
    "        shutil.move(c, \"test/cat\" )\n",
    "    for c in random.sample(glob.glob(\"train1/dog*\"), 100):\n",
    "        shutil.move(c, \"test/dog\" )\n",
    "\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2880fe-fb5c-4049-adfc-eb67154404cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path variables\n",
    "train_path = \"data/dogs-vs-cats/train\"\n",
    "val_path = \"data/dogs-vs-cats/val\"\n",
    "test_path = \"data/dogs-vs-cats/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f4846fb-27f6-4168-9b5c-e2f1fd3b2de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creates keras image generator. Applies vgg16 preprocessing to images first.\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=train_path, target_size=(224, 224), classes=[\"cat\", \"dog\"], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f90420e-5c6d-43c4-9796-f689cf56623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creates keras image generator. Applies vgg16 preprocessing to images first.\n",
    "val_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=val_path, target_size=(224, 224), classes=[\"cat\", \"dog\"], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd470182-f42d-46bb-92e0-3e3bf6a3eb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Creates keras image generator. Applies vgg16 preprocessing to images first.\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=test_path, target_size=(224, 224), classes=[\"cat\", \"dog\"], batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c6b8f20-f83e-4d1b-8460-544b27db752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying the correct number of images\n",
    "assert train_batches.n == 2000\n",
    "assert val_batches.n == 1000\n",
    "assert test_batches.n == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cad6247a-fde3-417e-8424-7a3f06d0fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying the correct number of classes\n",
    "assert train_batches.num_classes == val_batches.num_classes == test_batches.num_classes == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79863c53-9844-46cb-98fa-56576988909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25533de7-d508-4bf3-96e2-51078816f2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
